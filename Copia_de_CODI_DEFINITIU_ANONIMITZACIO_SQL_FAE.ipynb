{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGzZnIWZxCPO8wl+65hmxo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IgnasiOliveras/anonimitzar/blob/main/Copia_de_CODI_DEFINITIU_ANONIMITZACIO_SQL_FAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umQzWxiD0koF",
        "outputId": "0b581b8a-b714-4366-d9ae-d5267ff2954b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/981.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m972.8/981.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=732b917f70352f634df8ccb4d1c85471e91b3ea9a7daaadec63bc70c39691c93\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n",
            "Collecting deep_translator\n",
            "  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.11/dist-packages (from deep_translator) (4.13.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from deep_translator) (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2025.1.31)\n",
            "Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deep_translator\n",
            "Successfully installed deep_translator-1.11.4\n",
            "Collecting faker\n",
            "  Downloading Faker-36.1.1-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.1)\n",
            "Downloading Faker-36.1.1-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-36.1.1\n"
          ]
        }
      ],
      "source": [
        "! pip install langdetect\n",
        "! pip install deep_translator\n",
        "! pip install faker\n",
        "\n",
        "\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "from langdetect import detect\n",
        "from deep_translator import GoogleTranslator\n",
        "from faker import Faker\n",
        "import re\n",
        "\n",
        "def traducir_texto(texto):\n",
        "    \"\"\"Traduce las líneas que no están en español.\"\"\"\n",
        "    lineas = texto.split('\\n')\n",
        "    lineas_traducidas = []\n",
        "\n",
        "    for linea in lineas:\n",
        "        try:\n",
        "            idioma = detect(linea)\n",
        "            if idioma != 'es':\n",
        "                linea = GoogleTranslator(source='auto', target='es').translate(linea)\n",
        "        except:\n",
        "            pass  # Si no se puede detectar el idioma, se deja la línea igual\n",
        "\n",
        "        lineas_traducidas.append(linea)\n",
        "\n",
        "    return '\\n'.join(lineas_traducidas)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import re\n",
        "from faker import Faker\n",
        "import spacy\n",
        "!python -m spacy download es_core_news_sm\n",
        "def anonymizar_texto(texto):\n",
        "    \"\"\"Anonimiza datos sensibles en el texto, incluyendo nombres detectados por NER y frases específicas.\"\"\"\n",
        "    fake_es = Faker('es_ES')\n",
        "\n",
        "\n",
        "    # Mapa para almacenar placeholders y sus nombres falsos correspondientes\n",
        "    placeholder_map = {}\n",
        "    placeholder_counter = 0\n",
        "\n",
        "    # Patrones para detectar frases específicas y su idioma correspondiente\n",
        "    patterns = [(r'(Me llamo\\s+)([^.,;]+)', 'es')]  # Español\n",
        "\n",
        "\n",
        "    # Procesar cada patrón para reemplazar nombres con placeholders\n",
        "    for pattern, lang in patterns:\n",
        "        matches = list(re.finditer(pattern, texto, flags=re.IGNORECASE))\n",
        "        for match in reversed(matches):  # Procesar en orden inverso para evitar cambios en los offsets\n",
        "            start_name = match.start(2)\n",
        "            end_name = match.end(2)\n",
        "            original_name = match.group(2).strip()\n",
        "\n",
        "            # Generar nombre falso según el idioma\n",
        "            if lang == 'es':\n",
        "                fake_name = fake_es.name()\n",
        "\n",
        "\n",
        "            # Crear y almacenar placeholder\n",
        "            placeholder = f'{{{{NAME_{placeholder_counter}}}}}'\n",
        "            placeholder_map[placeholder] = fake_name\n",
        "            placeholder_counter += 1\n",
        "\n",
        "            # Reemplazar el nombre original con el placeholder\n",
        "            texto = texto[:start_name] + placeholder + texto[end_name:]\n",
        "\n",
        "    # Anonimizar números de teléfono y DNI\n",
        "    texto = re.sub(r'\\b\\d{9}\\b', lambda x: fake_es.phone_number(), texto)\n",
        "    texto = re.sub(r'\\b\\d{8}[A-Za-z]\\b', lambda x: fake_es.ssn(), texto)\n",
        "\n",
        "    # Cargar modelo de NER en español\n",
        "    nlp = spacy.load(\"es_core_news_sm\")\n",
        "    doc = nlp(texto)\n",
        "    replacements = []\n",
        "\n",
        "    # Detectar y reemplazar nombres mediante NER\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"PER\":\n",
        "            start = ent.start_char\n",
        "            end = ent.end_char\n",
        "            fake_name = fake_es.name()\n",
        "            replacements.append((start, end, fake_name))\n",
        "\n",
        "    # Aplicar reemplazos de NER en orden inverso\n",
        "    for start, end, fake_name in sorted(replacements, key=lambda x: -x[0]):\n",
        "        texto = texto[:start] + fake_name + texto[end:]\n",
        "\n",
        "    # Reemplazar placeholders con nombres falsos correspondientes\n",
        "    for placeholder, fake_name in placeholder_map.items():\n",
        "        texto = texto.replace(placeholder, fake_name)\n",
        "\n",
        "    return texto\n",
        "\n",
        "def procesar_texto(texto):\n",
        "    \"\"\"Traduce el texto al español y luego aplica la anonimización.\"\"\"\n",
        "    # Asumiendo que existe una función traducir_texto definida en otro lugar\n",
        "    texto_traducido = traducir_texto(texto)\n",
        "    texto_anonimizado = anonymizar_texto(texto_traducido)\n",
        "    return texto_anonimizado"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4daUa3_0sgK",
        "outputId": "568762cf-9a69-4336-b45f-f5430a7ff412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting es-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from es-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conectar a la base de datos y crear la tabla\n",
        "with sqlite3.connect(\"mi_base_de_datos.db\") as conn:\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS mi_tabla (\n",
        "        id INTEGER PRIMARY KEY,\n",
        "        body TEXT,\n",
        "        secret TEXT,\n",
        "        direction TEXT,\n",
        "        createdAt TEXT,\n",
        "        OpenchannelAccountId INTEGER,\n",
        "        OpenchannelInteractionId INTEGER,\n",
        "        UserId INTEGER,\n",
        "        ContactId INTEGER,\n",
        "        AttachmentId INTEGER,\n",
        "        sentBy TEXT\n",
        "    );\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "\n",
        "    # Cargar datos desde Excel a la base de datos\n",
        "    df = pd.read_excel(\"/content/MOSTRA_1.xlsx\")  # Reemplazar con el nombre real del archivo\n",
        "    df.to_sql(\"mi_tabla\", conn, if_exists=\"replace\", index=False)\n",
        "\n",
        "    # Extraer la columna body\n",
        "    df_body = pd.read_sql(\"SELECT id, body, createdAt, direction, ContactId FROM mi_tabla\", conn)\n",
        "\n",
        "    # Aplicar procesamiento a la columna body\n",
        "    df_body['body'] = df_body['body'].apply(procesar_texto)\n",
        "\n",
        "    # Actualizar la base de datos con los valores procesados\n",
        "    for index, row in df_body.iterrows():\n",
        "        cursor.execute(\"UPDATE mi_tabla SET body = ? WHERE id = ?\", (row['body'], row['id']))\n",
        "\n",
        "    conn.commit()\n",
        "\n",
        "print(\"Base de datos creada y procesamiento completado.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPjP4UwH1Lx7",
        "outputId": "46a70dac-bd2d-4e25-a881-1f5f4bfdb413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base de datos creada y procesamiento completado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_body.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bu4LIRdA3LuG",
        "outputId": "a9d82852-e13e-4109-b343-54d46584657b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id                                               body  \\\n",
            "0  77623                                               Hola   \n",
            "1  77624  Bienvenido a * Chat de apoyo emocional para jó...   \n",
            "2  77625                  Me llamo Nieves Montalbán Carnero   \n",
            "3  77626                                              Hola!   \n",
            "4  77627  Antes de empezar a chatear, es necesario que l...   \n",
            "\n",
            "             createdAt direction  ContactId  \n",
            "0  2023-01-01 00:10:19        in        466  \n",
            "1  2023-01-01 00:10:19       out        466  \n",
            "2  2023-01-01 00:10:37        in        466  \n",
            "3  2023-01-01 00:11:12       out        466  \n",
            "4  2023-01-01 00:11:33       out        466  \n"
          ]
        }
      ]
    }
  ]
}