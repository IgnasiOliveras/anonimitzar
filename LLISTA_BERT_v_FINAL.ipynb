{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAnyj8NzEf05iQ4L2FDv55",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IgnasiOliveras/anonimitzar/blob/main/LLISTA_BERT_v_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsycLeTucGBW",
        "outputId": "def4567f-6681-40a2-9ff6-0a55d071ee20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando preprocesamiento...\n",
            "Preprocesamiento completado. Archivo guardado como 'MOSTRA_1_preprocesado.xlsx'\n",
            "Iniciando anonimizaci√≥n...\n",
            "Anonimizaci√≥n completada. Archivos guardados como 'MOSTRA_1_anonimizado.xlsx' y 'cambios_anonimizacion.xlsx'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "\n",
        "# Funci√≥n de preprocesamiento\n",
        "def preprocesar_texto(texto):\n",
        "    \"\"\"Convierte el texto a min√∫sculas y elimina signos de puntuaci√≥n.\"\"\"\n",
        "    texto = texto.lower()\n",
        "    texto = re.sub(r'[^\\w\\s√Å√â√ç√ì√ö√°√©√≠√≥√∫√ë√±]', '', texto)\n",
        "    return texto\n",
        "\n",
        "# Paso 1: Preprocesamiento\n",
        "print(\"Iniciando preprocesamiento...\")\n",
        "\n",
        "# Cargar datos desde el archivo Excel\n",
        "df = pd.read_excel(\"MOSTRA_1.xlsx\")\n",
        "\n",
        "# Aplicar preprocesamiento a la columna 'body'\n",
        "df[\"body_preprocesado\"] = df[\"body\"].astype(str).apply(preprocesar_texto)\n",
        "\n",
        "# Guardar el archivo preprocesado\n",
        "df.to_excel(\"MOSTRA_1_preprocesado.xlsx\", index=False)\n",
        "\n",
        "print(\"Preprocesamiento completado. Archivo guardado como 'MOSTRA_1_preprocesado.xlsx'\")\n",
        "\n",
        "# Paso 2: Anonimizaci√≥n\n",
        "print(\"Iniciando anonimizaci√≥n...\")\n",
        "\n",
        "# Cargar lista de nombres desde el archivo CSV\n",
        "nombres_df = pd.read_csv(\"2024_pad_m_nom_sexe.csv\")\n",
        "\n",
        "# Filtrar nombres por g√©nero (convertir a min√∫sculas y eliminar espacios extra)\n",
        "nombres_masculinos = set(nombres_df[nombres_df[\"SEXE\"] == 2][\"NOM\"].str.strip().str.lower().tolist())\n",
        "nombres_femeninos = set(nombres_df[nombres_df[\"SEXE\"] == 1][\"NOM\"].str.strip().str.lower().tolist())\n",
        "\n",
        "# Lista de palabras comunes que no deben anonimizarse\n",
        "palabras_excluidas = {\"bo\",\"d'una\",\"dan\",\"justo\",\"salud\",\"li\",\"leo\",\"te\",\"ella\", \"el\", \"los\", \"las\", \"nosotros\", \"vosotros\",\n",
        "                      \"usted\", \"ustedes\", \"ellos\", \"ellas\", \"su\", \"sus\", \"un\", \"una\", \"unos\", \"unas\", \"nada\", \"mira\", \"duna\",\n",
        "                      \"rabia\", \"dora\", \"saba\", \"esperanza\", \"domingo\",\"sol\"}\n",
        "\n",
        "# Diccionario para mantener consistencia de nombres inventados\n",
        "nombre_map = {}\n",
        "cambios = []  # Lista para registrar los cambios\n",
        "\n",
        "def detectar_genero(nombre):\n",
        "    \"\"\"Detecta si un nombre es masculino o femenino basado en la lista cargada.\"\"\"\n",
        "    nombre = nombre.lower()\n",
        "    if nombre in nombres_masculinos:\n",
        "        return \"male\"\n",
        "    elif nombre in nombres_femeninos:\n",
        "        return \"female\"\n",
        "    return \"neutral\"\n",
        "\n",
        "def mantener_formato(original, nuevo):\n",
        "    \"\"\"Ajusta el formato del nuevo nombre para que coincida con el original.\"\"\"\n",
        "    if original.istitle():  # Primera letra may√∫scula\n",
        "        return nuevo.title()\n",
        "    elif original.isupper():  # Todo en may√∫sculas\n",
        "        return nuevo.upper()\n",
        "    else:  # Todo en min√∫sculas\n",
        "        return nuevo.lower()\n",
        "\n",
        "def generar_nombre(original_name):\n",
        "    \"\"\"Genera un nombre ficticio manteniendo el g√©nero y la cantidad de palabras.\"\"\"\n",
        "    palabras = original_name.split()\n",
        "    num_palabras = len(palabras)\n",
        "\n",
        "    if original_name in nombre_map:\n",
        "        return nombre_map[original_name]\n",
        "\n",
        "    genero = detectar_genero(palabras[0])\n",
        "    nuevo_nombre = []\n",
        "\n",
        "    for _ in range(num_palabras):\n",
        "        if genero == \"male\":\n",
        "            nuevo_nombre.append(random.choice(list(nombres_masculinos)))\n",
        "        else:\n",
        "            nuevo_nombre.append(random.choice(list(nombres_femeninos)))\n",
        "\n",
        "    nombre_final = \" \".join(nuevo_nombre)\n",
        "    nombre_final = mantener_formato(original_name, nombre_final)\n",
        "\n",
        "    nombre_map[original_name] = nombre_final\n",
        "    return nombre_final\n",
        "\n",
        "def anonimizar_texto(texto):\n",
        "    \"\"\"Reemplaza nombres en el texto por versiones anonimizadas manteniendo consistencia.\"\"\"\n",
        "    # Convert the input to a string before calling split\n",
        "    texto = str(texto)\n",
        "    palabras = texto.split()\n",
        "    texto_anonimizado = []\n",
        "\n",
        "    for i, palabra in enumerate(palabras):\n",
        "        palabra_limpia = re.sub(r'[^A-Za-z√Å√â√ç√ì√ö√°√©√≠√≥√∫√ë√±]', '', palabra).lower()\n",
        "        if palabra_limpia in nombres_masculinos or palabra_limpia in nombres_femeninos:\n",
        "            if palabra_limpia not in palabras_excluidas:\n",
        "                nombre_anonimizado = generar_nombre(palabra)\n",
        "                texto_anonimizado.append(nombre_anonimizado)\n",
        "\n",
        "                # Get 3 previous words\n",
        "                palabra_anterior = \" \".join(palabras[i-3:i]) if i >= 3 else \" \".join(palabras[:i])\n",
        "                # Get 3 posterior words\n",
        "                palabra_posterior = \" \".join(palabras[i+1:i+4]) if i < len(palabras) - 3 else \" \".join(palabras[i+1:])\n",
        "\n",
        "                cambios.append((palabra, nombre_anonimizado, palabra_anterior, palabra_posterior))\n",
        "            else:\n",
        "                texto_anonimizado.append(palabra)\n",
        "        else:\n",
        "            texto_anonimizado.append(palabra)\n",
        "\n",
        "    return \" \".join(texto_anonimizado)\n",
        "# Cargar el archivo preprocesado\n",
        "df_preprocesado = pd.read_excel(\"MOSTRA_1_preprocesado.xlsx\")\n",
        "\n",
        "# Aplicar anonimizaci√≥n a la columna 'body_preprocesado'\n",
        "df_preprocesado[\"body_anonimizado\"] = df_preprocesado[\"body_preprocesado\"].apply(anonimizar_texto)\n",
        "\n",
        "# Guardar el archivo anonimizado\n",
        "df_preprocesado.to_excel(\"MOSTRA_1_anonimizado.xlsx\", index=False)\n",
        "\n",
        "# Crear DataFrame con los cambios y guardarlo en un archivo separado\n",
        "cambios_df = pd.DataFrame(cambios, columns=[\"Original\", \"Anonimizado\", \"Palabra_Anterior\", \"Palabra_Posterior\"])\n",
        "cambios_df.to_excel(\"cambios_anonimizacion.xlsx\", index=False)\n",
        "\n",
        "print(\"Anonimizaci√≥n completada. Archivos guardados como 'MOSTRA_1_anonimizado.xlsx' y 'cambios_anonimizacion.xlsx'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "!python -m spacy download es_core_news_sm\n",
        "\n",
        "# Cargar modelo de spaCy en espa√±ol\n",
        "nlp = spacy.load(\"es_core_news_sm\")\n",
        "\n",
        "# Funci√≥n de preprocesamiento\n",
        "def preprocesar_texto(texto):\n",
        "    \"\"\"Convierte el texto a min√∫sculas y elimina signos de puntuaci√≥n.\"\"\"\n",
        "    texto = texto.lower()\n",
        "    texto = re.sub(r'[^\\w\\s√Å√â√ç√ì√ö√°√©√≠√≥√∫√ë√±]', '', texto)\n",
        "    return texto\n",
        "\n",
        "# Cargar datos desde el archivo Excel\n",
        "df = pd.read_excel(\"MOSTRA_1.xlsx\")\n",
        "\n",
        "# Aplicar preprocesamiento\n",
        "df[\"body_preprocesado\"] = df[\"body\"].astype(str).apply(preprocesar_texto)\n",
        "\n",
        "# Guardar preprocesado\n",
        "df.to_excel(\"MOSTRA_1_preprocesado.xlsx\", index=False)\n",
        "\n",
        "# Cargar lista de nombres\n",
        "nombres_df = pd.read_csv(\"2024_pad_m_nom_sexe.csv\")\n",
        "nombres_masculinos = set(nombres_df[nombres_df[\"SEXE\"] == 2][\"NOM\"].str.strip().str.lower().tolist())\n",
        "nombres_femeninos = set(nombres_df[nombres_df[\"SEXE\"] == 1][\"NOM\"].str.strip().str.lower().tolist())\n",
        "\n",
        "# Palabras que no se deben anonimizar\n",
        "palabras_excluidas = {\"bo\", \"d'una\", \"dan\", \"justo\", \"salud\", \"li\", \"leo\", \"te\", \"ella\", \"el\", \"los\", \"las\",\n",
        "                      \"nosotros\", \"vosotros\", \"usted\", \"ustedes\", \"ellos\", \"ellas\", \"su\", \"sus\", \"un\", \"una\", \"unos\",\n",
        "                      \"unas\", \"nada\", \"mira\", \"duna\", \"rabia\", \"dora\", \"saba\", \"esperanza\", \"domingo\", \"sol\"}\n",
        "\n",
        "# Diccionario para consistencia en anonimizaci√≥n\n",
        "nombre_map = {}\n",
        "cambios = []\n",
        "\n",
        "# Funciones auxiliares\n",
        "def detectar_genero(nombre):\n",
        "    nombre = nombre.lower()\n",
        "    if nombre in nombres_masculinos:\n",
        "        return \"male\"\n",
        "    elif nombre in nombres_femeninos:\n",
        "        return \"female\"\n",
        "    return \"neutral\"\n",
        "\n",
        "def mantener_formato(original, nuevo):\n",
        "    if original.istitle():\n",
        "        return nuevo.title()\n",
        "    elif original.isupper():\n",
        "        return nuevo.upper()\n",
        "    return nuevo.lower()\n",
        "\n",
        "def generar_nombre(original_name):\n",
        "    palabras = original_name.split()\n",
        "    num_palabras = len(palabras)\n",
        "\n",
        "    if original_name in nombre_map:\n",
        "        return nombre_map[original_name]\n",
        "\n",
        "    genero = detectar_genero(palabras[0])\n",
        "    nuevo_nombre = []\n",
        "\n",
        "    for _ in range(num_palabras):\n",
        "        if genero == \"male\":\n",
        "            nuevo_nombre.append(random.choice(list(nombres_masculinos)))\n",
        "        else:\n",
        "            nuevo_nombre.append(random.choice(list(nombres_femeninos)))\n",
        "\n",
        "    nombre_final = \" \".join(nuevo_nombre)\n",
        "    nombre_final = mantener_formato(original_name, nombre_final)\n",
        "\n",
        "    nombre_map[original_name] = nombre_final\n",
        "    return nombre_final\n",
        "\n",
        "def anonimizar_texto(texto):\n",
        "    texto = str(texto)\n",
        "    palabras = texto.split()\n",
        "    texto_anonimizado = []\n",
        "\n",
        "    for i, palabra in enumerate(palabras):\n",
        "        palabra_limpia = re.sub(r'[^A-Za-z√Å√â√ç√ì√ö√°√©√≠√≥√∫√ë√±]', '', palabra).lower()\n",
        "        if palabra_limpia in nombres_masculinos or palabra_limpia in nombres_femeninos:\n",
        "            if palabra_limpia not in palabras_excluidas:\n",
        "                nombre_anonimizado = generar_nombre(palabra)\n",
        "                texto_anonimizado.append(nombre_anonimizado)\n",
        "\n",
        "                palabra_anterior = \" \".join(palabras[i-3:i]) if i >= 3 else \" \".join(palabras[:i])\n",
        "                palabra_posterior = \" \".join(palabras[i+1:i+4]) if i < len(palabras) - 3 else \" \".join(palabras[i+1:])\n",
        "\n",
        "                cambios.append((palabra, nombre_anonimizado, palabra_anterior, palabra_posterior))\n",
        "            else:\n",
        "                texto_anonimizado.append(palabra)\n",
        "        else:\n",
        "            texto_anonimizado.append(palabra)\n",
        "\n",
        "    return \" \".join(texto_anonimizado)\n",
        "\n",
        "# Cargar datos preprocesados\n",
        "df_preprocesado = pd.read_excel(\"MOSTRA_1_preprocesado.xlsx\")\n",
        "\n",
        "# Aplicar anonimizaci√≥n\n",
        "df_preprocesado[\"body_anonimizado\"] = df_preprocesado[\"body_preprocesado\"].apply(anonimizar_texto)\n",
        "\n",
        "# Guardar anonimizado\n",
        "df_preprocesado.to_excel(\"MOSTRA_1_anonimizado.xlsx\", index=False)\n",
        "\n",
        "# Guardar cambios en nombres\n",
        "cambios_df = pd.DataFrame(cambios, columns=[\"Original\", \"Anonimizado\", \"Palabra_Anterior\", \"Palabra_Posterior\"])\n",
        "cambios_df.to_excel(\"cambios_anonimizacion.xlsx\", index=False)\n",
        "\n",
        "print(\"Anonimizaci√≥n completada. Ejecutando NER para validaci√≥n...\")\n",
        "\n",
        "### üîç Integraci√≥n con spaCy NER\n",
        "def extraer_entidades(texto):\n",
        "    \"\"\"Extrae entidades nombradas de un texto usando spaCy.\"\"\"\n",
        "    doc = nlp(str(texto))\n",
        "    return {ent.text for ent in doc.ents}  # Devolver conjunto de entidades √∫nicas\n",
        "\n",
        "# Aplicar NER en ambas versiones\n",
        "df_preprocesado[\"entidades_original\"] = df[\"body\"].apply(extraer_entidades)\n",
        "df_preprocesado[\"entidades_anonimizado\"] = df_preprocesado[\"body_anonimizado\"].apply(extraer_entidades)\n",
        "\n",
        "# Comparar entidades y decidir si revertir al texto original\n",
        "def restaurar_si_cambia(row):\n",
        "    if row[\"entidades_original\"] != row[\"entidades_anonimizado\"]:\n",
        "        return row[\"body\"]  # Restaurar original si hay cambios\n",
        "    return row[\"body_anonimizado\"]  # Mantener anonimizado si no hay cambios\n",
        "\n",
        "df_preprocesado[\"body_final\"] = df_preprocesado.apply(restaurar_si_cambia, axis=1)\n",
        "\n",
        "# Guardar resultado final\n",
        "df_preprocesado.to_excel(\"MOSTRA_1_final.xlsx\", index=False)\n",
        "\n",
        "print(\"Proceso completo. Archivo guardado como 'MOSTRA_1_final.xlsx'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ro7Hhbc5lXRp",
        "outputId": "cf556d0a-1ad9-4053-e415-18412a53e415"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting es-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from es-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Anonimizaci√≥n completada. Ejecutando NER para validaci√≥n...\n",
            "Proceso completo. Archivo guardado como 'MOSTRA_1_final.xlsx'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "# Cargar modelo de spaCy en espa√±ol\n",
        "nlp = spacy.load(\"es_core_news_sm\")\n",
        "\n",
        "# Cargar datos\n",
        "df = pd.read_excel(\"MOSTRA_1_anonimizado.xlsx\")\n",
        "df_original = pd.read_excel(\"MOSTRA_1.xlsx\")\n",
        "\n",
        "# üîç Funci√≥n para extraer nombres de persona\n",
        "def extraer_nombres_persona(texto):\n",
        "    \"\"\"Extrae solo nombres de persona detectados por spaCy.\"\"\"\n",
        "    doc = nlp(str(texto))\n",
        "    return {ent.text for ent in doc.ents if ent.label_ == \"PER\"}  # Filtrar solo entidades de persona\n",
        "\n",
        "# Aplicar extracci√≥n de nombres de persona\n",
        "df[\"nombres_original\"] = df_original[\"body\"].apply(extraer_nombres_persona)\n",
        "df[\"nombres_anonimizado\"] = df[\"body_anonimizado\"].apply(extraer_nombres_persona)\n",
        "\n",
        "# Guardar el resultado en un archivo Excel\n",
        "df.to_excel(\"MOSTRA_1_nombres_detectados.xlsx\", index=False)\n",
        "\n",
        "# Mostrar los primeros resultados\n",
        "print(df[[\"nombres_original\", \"nombres_anonimizado\"]].head())\n",
        "\n",
        "print(\"Proceso completado. Archivo guardado como 'MOSTRA_1_nombres_detectados.xlsx'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7IiITRRnYgd",
        "outputId": "c64c8ddc-49db-4c83-d2e8-074eae9448a3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  nombres_original     nombres_anonimizado\n",
            "0               {}                      {}\n",
            "1     {Bienvenido}  {benvingutda, tatenem}\n",
            "2               {}                      {}\n",
            "3               {}                      {}\n",
            "4               {}                      {}\n",
            "Proceso completado. Archivo guardado como 'MOSTRA_1_nombres_detectados.xlsx'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import torch\n",
        "import time\n",
        "from transformers import AutoModelForTokenClassification, AutoTokenizer, pipeline\n",
        "\n",
        "# üöÄ Iniciar timer global\n",
        "inicio_total = time.time()\n",
        "\n",
        "# üöÄ Cargar modelo NER con XLM-RoBERTa\n",
        "print(\"üîπ Cargando modelo NER...\")\n",
        "inicio = time.time()\n",
        "modelo_ner = \"MMG/xlm-roberta-large-ner-spanish\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(modelo_ner)\n",
        "modelo = AutoModelForTokenClassification.from_pretrained(modelo_ner)\n",
        "nlp_ner = pipeline(\"ner\", model=modelo, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
        "print(f\"‚úÖ Modelo cargado en {time.time() - inicio:.2f} segundos.\\n\")\n",
        "\n",
        "# üìå Funci√≥n para extraer nombres de persona con XLM-RoBERTa\n",
        "def extraer_nombres_ner(texto):\n",
        "    \"\"\"Extrae nombres de persona usando XLM-RoBERTa.\"\"\"\n",
        "    if not isinstance(texto, str) or texto.strip() == \"\":\n",
        "        return set()\n",
        "    entidades = nlp_ner(texto)\n",
        "    return {ent[\"word\"] for ent in entidades if ent[\"entity_group\"] == \"PER\"}\n",
        "\n",
        "# üìå Funci√≥n de preprocesamiento\n",
        "def preprocesar_texto(texto):\n",
        "    return re.sub(r'[^\\w\\s√Å√â√ç√ì√ö√°√©√≠√≥√∫√ë√±]', '', texto.lower())\n",
        "\n",
        "# üìÇ Cargar datos\n",
        "print(\"üîπ Cargando datos...\")\n",
        "inicio = time.time()\n",
        "df = pd.read_excel(\"MOSTRA_1.xlsx\")\n",
        "df[\"body_preprocesado\"] = df[\"body\"].astype(str).apply(preprocesar_texto)\n",
        "print(f\"‚úÖ Datos cargados en {time.time() - inicio:.2f} segundos.\\n\")\n",
        "\n",
        "# üìå Cargar lista de nombres\n",
        "print(\"üîπ Cargando lista de nombres...\")\n",
        "inicio = time.time()\n",
        "nombres_df = pd.read_csv(\"2024_pad_m_nom_sexe.csv\")\n",
        "nombres_masculinos = set(nombres_df[nombres_df[\"SEXE\"] == 2][\"NOM\"].str.strip().str.lower().tolist())\n",
        "nombres_femeninos = set(nombres_df[nombres_df[\"SEXE\"] == 1][\"NOM\"].str.strip().str.lower().tolist())\n",
        "print(f\"‚úÖ Lista de nombres cargada en {time.time() - inicio:.2f} segundos.\\n\")\n",
        "\n",
        "# üìå Palabras que no se deben anonimizar\n",
        "palabras_excluidas = {\"bo\", \"d'una\", \"justo\", \"salud\", \"leo\", \"te\", \"ella\", \"el\", \"los\", \"las\"}\n",
        "\n",
        "# üìå Diccionario para mantener consistencia en la anonimizaci√≥n\n",
        "nombre_map = {}\n",
        "cambios = []\n",
        "\n",
        "def detectar_genero(nombre):\n",
        "    nombre = nombre.lower()\n",
        "    return \"male\" if nombre in nombres_masculinos else \"female\" if nombre in nombres_femeninos else \"neutral\"\n",
        "\n",
        "def mantener_formato(original, nuevo):\n",
        "    return nuevo.title() if original.istitle() else nuevo.upper() if original.isupper() else nuevo.lower()\n",
        "\n",
        "def generar_nombre(original_name):\n",
        "    if original_name in nombre_map:\n",
        "        return nombre_map[original_name]\n",
        "    genero = detectar_genero(original_name.split()[0])\n",
        "    nuevo_nombre = random.choice(list(nombres_masculinos if genero == \"male\" else nombres_femeninos))\n",
        "    nombre_map[original_name] = mantener_formato(original_name, nuevo_nombre)\n",
        "    return nombre_map[original_name]\n",
        "\n",
        "# üîç Aplicar anonimizaci√≥n y registrar cambios\n",
        "print(\"üîπ Iniciando anonimizaci√≥n...\")\n",
        "inicio = time.time()\n",
        "total_filas = len(df)\n",
        "df[\"body_anonimizado\"], df[\"cambio_realizado\"] = zip(*df[\"body_preprocesado\"].apply(lambda x: anonimizar_texto(x)))\n",
        "\n",
        "# ‚è≥ Tiempo total estimado\n",
        "tiempo_anonimizacion = time.time() - inicio\n",
        "print(f\"‚úÖ Anonimizaci√≥n completada en {tiempo_anonimizacion:.2f} segundos.\\n\")\n",
        "\n",
        "# üîç Aplicar NER **solo en textos donde hubo cambios**\n",
        "print(\"üîπ Aplicando NER solo en textos modificados...\")\n",
        "inicio = time.time()\n",
        "df[\"nombres_original\"] = df.apply(lambda row: extraer_nombres_ner(row[\"body\"]) if row[\"cambio_realizado\"] else set(), axis=1)\n",
        "df[\"nombres_anonimizado\"] = df.apply(lambda row: extraer_nombres_ner(row[\"body_anonimizado\"]) if row[\"cambio_realizado\"] else set(), axis=1)\n",
        "print(f\"‚úÖ NER aplicado en {time.time() - inicio:.2f} segundos.\\n\")\n",
        "\n",
        "# üìå Comparar nombres detectados antes y despu√©s de la anonimizaci√≥n\n",
        "print(\"üîπ Comparando nombres originales y anonimizados...\")\n",
        "inicio = time.time()\n",
        "df[\"body_final\"] = df.apply(lambda row: row[\"body\"] if row[\"nombres_original\"] != row[\"nombres_anonimizado\"] else row[\"body_anonimizado\"], axis=1)\n",
        "print(f\"‚úÖ Comparaci√≥n completada en {time.time() - inicio:.2f} segundos.\\n\")\n",
        "\n",
        "# üìÇ Guardar resultado final\n",
        "print(\"üîπ Guardando resultado final...\")\n",
        "inicio = time.time()\n",
        "df.to_excel(\"MOSTRA_1_final.xlsx\", index=False)\n",
        "print(f\"‚úÖ Archivo guardado en {time.time() - inicio:.2f} segundos.\\n\")\n",
        "\n",
        "# ‚è≥ Tiempo total de ejecuci√≥n\n",
        "print(f\"‚è≥ Tiempo total de ejecuci√≥n: {time.time() - inicio_total:.2f} segundos.\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYt33VZypJNU",
        "outputId": "3e295a2d-f0c4-494b-def7-4d6b28b848bc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Cargando modelo NER...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo cargado en 6.16 segundos.\n",
            "\n",
            "üîπ Cargando datos...\n",
            "‚úÖ Datos cargados en 4.64 segundos.\n",
            "\n",
            "üîπ Cargando lista de nombres...\n",
            "‚úÖ Lista de nombres cargada en 0.01 segundos.\n",
            "\n",
            "üîπ Iniciando anonimizaci√≥n...\n",
            "‚úÖ Anonimizaci√≥n completada en 0.10 segundos.\n",
            "\n",
            "üîπ Aplicando NER solo en textos modificados...\n",
            "‚úÖ NER aplicado en 851.36 segundos.\n",
            "\n",
            "üîπ Comparando nombres originales y anonimizados...\n",
            "‚úÖ Comparaci√≥n completada en 0.09 segundos.\n",
            "\n",
            "üîπ Guardando resultado final...\n",
            "‚úÖ Archivo guardado en 5.58 segundos.\n",
            "\n",
            "‚è≥ Tiempo total de ejecuci√≥n: 867.95 segundos.\n"
          ]
        }
      ]
    }
  ]
}