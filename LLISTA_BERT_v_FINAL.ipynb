{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAnyj8NzEf05iQ4L2FDv55",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IgnasiOliveras/anonimitzar/blob/main/LLISTA_BERT_v_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsycLeTucGBW",
        "outputId": "def4567f-6681-40a2-9ff6-0a55d071ee20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando preprocesamiento...\n",
            "Preprocesamiento completado. Archivo guardado como 'MOSTRA_1_preprocesado.xlsx'\n",
            "Iniciando anonimización...\n",
            "Anonimización completada. Archivos guardados como 'MOSTRA_1_anonimizado.xlsx' y 'cambios_anonimizacion.xlsx'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "\n",
        "# Función de preprocesamiento\n",
        "def preprocesar_texto(texto):\n",
        "    \"\"\"Convierte el texto a minúsculas y elimina signos de puntuación.\"\"\"\n",
        "    texto = texto.lower()\n",
        "    texto = re.sub(r'[^\\w\\sÁÉÍÓÚáéíóúÑñ]', '', texto)\n",
        "    return texto\n",
        "\n",
        "# Paso 1: Preprocesamiento\n",
        "print(\"Iniciando preprocesamiento...\")\n",
        "\n",
        "# Cargar datos desde el archivo Excel\n",
        "df = pd.read_excel(\"MOSTRA_1.xlsx\")\n",
        "\n",
        "# Aplicar preprocesamiento a la columna 'body'\n",
        "df[\"body_preprocesado\"] = df[\"body\"].astype(str).apply(preprocesar_texto)\n",
        "\n",
        "# Guardar el archivo preprocesado\n",
        "df.to_excel(\"MOSTRA_1_preprocesado.xlsx\", index=False)\n",
        "\n",
        "print(\"Preprocesamiento completado. Archivo guardado como 'MOSTRA_1_preprocesado.xlsx'\")\n",
        "\n",
        "# Paso 2: Anonimización\n",
        "print(\"Iniciando anonimización...\")\n",
        "\n",
        "# Cargar lista de nombres desde el archivo CSV\n",
        "nombres_df = pd.read_csv(\"2024_pad_m_nom_sexe.csv\")\n",
        "\n",
        "# Filtrar nombres por género (convertir a minúsculas y eliminar espacios extra)\n",
        "nombres_masculinos = set(nombres_df[nombres_df[\"SEXE\"] == 2][\"NOM\"].str.strip().str.lower().tolist())\n",
        "nombres_femeninos = set(nombres_df[nombres_df[\"SEXE\"] == 1][\"NOM\"].str.strip().str.lower().tolist())\n",
        "\n",
        "# Lista de palabras comunes que no deben anonimizarse\n",
        "palabras_excluidas = {\"bo\",\"d'una\",\"dan\",\"justo\",\"salud\",\"li\",\"leo\",\"te\",\"ella\", \"el\", \"los\", \"las\", \"nosotros\", \"vosotros\",\n",
        "                      \"usted\", \"ustedes\", \"ellos\", \"ellas\", \"su\", \"sus\", \"un\", \"una\", \"unos\", \"unas\", \"nada\", \"mira\", \"duna\",\n",
        "                      \"rabia\", \"dora\", \"saba\", \"esperanza\", \"domingo\",\"sol\"}\n",
        "\n",
        "# Diccionario para mantener consistencia de nombres inventados\n",
        "nombre_map = {}\n",
        "cambios = []  # Lista para registrar los cambios\n",
        "\n",
        "def detectar_genero(nombre):\n",
        "    \"\"\"Detecta si un nombre es masculino o femenino basado en la lista cargada.\"\"\"\n",
        "    nombre = nombre.lower()\n",
        "    if nombre in nombres_masculinos:\n",
        "        return \"male\"\n",
        "    elif nombre in nombres_femeninos:\n",
        "        return \"female\"\n",
        "    return \"neutral\"\n",
        "\n",
        "def mantener_formato(original, nuevo):\n",
        "    \"\"\"Ajusta el formato del nuevo nombre para que coincida con el original.\"\"\"\n",
        "    if original.istitle():  # Primera letra mayúscula\n",
        "        return nuevo.title()\n",
        "    elif original.isupper():  # Todo en mayúsculas\n",
        "        return nuevo.upper()\n",
        "    else:  # Todo en minúsculas\n",
        "        return nuevo.lower()\n",
        "\n",
        "def generar_nombre(original_name):\n",
        "    \"\"\"Genera un nombre ficticio manteniendo el género y la cantidad de palabras.\"\"\"\n",
        "    palabras = original_name.split()\n",
        "    num_palabras = len(palabras)\n",
        "\n",
        "    if original_name in nombre_map:\n",
        "        return nombre_map[original_name]\n",
        "\n",
        "    genero = detectar_genero(palabras[0])\n",
        "    nuevo_nombre = []\n",
        "\n",
        "    for _ in range(num_palabras):\n",
        "        if genero == \"male\":\n",
        "            nuevo_nombre.append(random.choice(list(nombres_masculinos)))\n",
        "        else:\n",
        "            nuevo_nombre.append(random.choice(list(nombres_femeninos)))\n",
        "\n",
        "    nombre_final = \" \".join(nuevo_nombre)\n",
        "    nombre_final = mantener_formato(original_name, nombre_final)\n",
        "\n",
        "    nombre_map[original_name] = nombre_final\n",
        "    return nombre_final\n",
        "\n",
        "def anonimizar_texto(texto):\n",
        "    \"\"\"Reemplaza nombres en el texto por versiones anonimizadas manteniendo consistencia.\"\"\"\n",
        "    # Convert the input to a string before calling split\n",
        "    texto = str(texto)\n",
        "    palabras = texto.split()\n",
        "    texto_anonimizado = []\n",
        "\n",
        "    for i, palabra in enumerate(palabras):\n",
        "        palabra_limpia = re.sub(r'[^A-Za-zÁÉÍÓÚáéíóúÑñ]', '', palabra).lower()\n",
        "        if palabra_limpia in nombres_masculinos or palabra_limpia in nombres_femeninos:\n",
        "            if palabra_limpia not in palabras_excluidas:\n",
        "                nombre_anonimizado = generar_nombre(palabra)\n",
        "                texto_anonimizado.append(nombre_anonimizado)\n",
        "\n",
        "                # Get 3 previous words\n",
        "                palabra_anterior = \" \".join(palabras[i-3:i]) if i >= 3 else \" \".join(palabras[:i])\n",
        "                # Get 3 posterior words\n",
        "                palabra_posterior = \" \".join(palabras[i+1:i+4]) if i < len(palabras) - 3 else \" \".join(palabras[i+1:])\n",
        "\n",
        "                cambios.append((palabra, nombre_anonimizado, palabra_anterior, palabra_posterior))\n",
        "            else:\n",
        "                texto_anonimizado.append(palabra)\n",
        "        else:\n",
        "            texto_anonimizado.append(palabra)\n",
        "\n",
        "    return \" \".join(texto_anonimizado)\n",
        "# Cargar el archivo preprocesado\n",
        "df_preprocesado = pd.read_excel(\"MOSTRA_1_preprocesado.xlsx\")\n",
        "\n",
        "# Aplicar anonimización a la columna 'body_preprocesado'\n",
        "df_preprocesado[\"body_anonimizado\"] = df_preprocesado[\"body_preprocesado\"].apply(anonimizar_texto)\n",
        "\n",
        "# Guardar el archivo anonimizado\n",
        "df_preprocesado.to_excel(\"MOSTRA_1_anonimizado.xlsx\", index=False)\n",
        "\n",
        "# Crear DataFrame con los cambios y guardarlo en un archivo separado\n",
        "cambios_df = pd.DataFrame(cambios, columns=[\"Original\", \"Anonimizado\", \"Palabra_Anterior\", \"Palabra_Posterior\"])\n",
        "cambios_df.to_excel(\"cambios_anonimizacion.xlsx\", index=False)\n",
        "\n",
        "print(\"Anonimización completada. Archivos guardados como 'MOSTRA_1_anonimizado.xlsx' y 'cambios_anonimizacion.xlsx'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "!python -m spacy download es_core_news_sm\n",
        "\n",
        "# Cargar modelo de spaCy en español\n",
        "nlp = spacy.load(\"es_core_news_sm\")\n",
        "\n",
        "# Función de preprocesamiento\n",
        "def preprocesar_texto(texto):\n",
        "    \"\"\"Convierte el texto a minúsculas y elimina signos de puntuación.\"\"\"\n",
        "    texto = texto.lower()\n",
        "    texto = re.sub(r'[^\\w\\sÁÉÍÓÚáéíóúÑñ]', '', texto)\n",
        "    return texto\n",
        "\n",
        "# Cargar datos desde el archivo Excel\n",
        "df = pd.read_excel(\"MOSTRA_1.xlsx\")\n",
        "\n",
        "# Aplicar preprocesamiento\n",
        "df[\"body_preprocesado\"] = df[\"body\"].astype(str).apply(preprocesar_texto)\n",
        "\n",
        "# Guardar preprocesado\n",
        "df.to_excel(\"MOSTRA_1_preprocesado.xlsx\", index=False)\n",
        "\n",
        "# Cargar lista de nombres\n",
        "nombres_df = pd.read_csv(\"2024_pad_m_nom_sexe.csv\")\n",
        "nombres_masculinos = set(nombres_df[nombres_df[\"SEXE\"] == 2][\"NOM\"].str.strip().str.lower().tolist())\n",
        "nombres_femeninos = set(nombres_df[nombres_df[\"SEXE\"] == 1][\"NOM\"].str.strip().str.lower().tolist())\n",
        "\n",
        "# Palabras que no se deben anonimizar\n",
        "palabras_excluidas = {\"bo\", \"d'una\", \"dan\", \"justo\", \"salud\", \"li\", \"leo\", \"te\", \"ella\", \"el\", \"los\", \"las\",\n",
        "                      \"nosotros\", \"vosotros\", \"usted\", \"ustedes\", \"ellos\", \"ellas\", \"su\", \"sus\", \"un\", \"una\", \"unos\",\n",
        "                      \"unas\", \"nada\", \"mira\", \"duna\", \"rabia\", \"dora\", \"saba\", \"esperanza\", \"domingo\", \"sol\"}\n",
        "\n",
        "# Diccionario para consistencia en anonimización\n",
        "nombre_map = {}\n",
        "cambios = []\n",
        "\n",
        "# Funciones auxiliares\n",
        "def detectar_genero(nombre):\n",
        "    nombre = nombre.lower()\n",
        "    if nombre in nombres_masculinos:\n",
        "        return \"male\"\n",
        "    elif nombre in nombres_femeninos:\n",
        "        return \"female\"\n",
        "    return \"neutral\"\n",
        "\n",
        "def mantener_formato(original, nuevo):\n",
        "    if original.istitle():\n",
        "        return nuevo.title()\n",
        "    elif original.isupper():\n",
        "        return nuevo.upper()\n",
        "    return nuevo.lower()\n",
        "\n",
        "def generar_nombre(original_name):\n",
        "    palabras = original_name.split()\n",
        "    num_palabras = len(palabras)\n",
        "\n",
        "    if original_name in nombre_map:\n",
        "        return nombre_map[original_name]\n",
        "\n",
        "    genero = detectar_genero(palabras[0])\n",
        "    nuevo_nombre = []\n",
        "\n",
        "    for _ in range(num_palabras):\n",
        "        if genero == \"male\":\n",
        "            nuevo_nombre.append(random.choice(list(nombres_masculinos)))\n",
        "        else:\n",
        "            nuevo_nombre.append(random.choice(list(nombres_femeninos)))\n",
        "\n",
        "    nombre_final = \" \".join(nuevo_nombre)\n",
        "    nombre_final = mantener_formato(original_name, nombre_final)\n",
        "\n",
        "    nombre_map[original_name] = nombre_final\n",
        "    return nombre_final\n",
        "\n",
        "def anonimizar_texto(texto):\n",
        "    texto = str(texto)\n",
        "    palabras = texto.split()\n",
        "    texto_anonimizado = []\n",
        "\n",
        "    for i, palabra in enumerate(palabras):\n",
        "        palabra_limpia = re.sub(r'[^A-Za-zÁÉÍÓÚáéíóúÑñ]', '', palabra).lower()\n",
        "        if palabra_limpia in nombres_masculinos or palabra_limpia in nombres_femeninos:\n",
        "            if palabra_limpia not in palabras_excluidas:\n",
        "                nombre_anonimizado = generar_nombre(palabra)\n",
        "                texto_anonimizado.append(nombre_anonimizado)\n",
        "\n",
        "                palabra_anterior = \" \".join(palabras[i-3:i]) if i >= 3 else \" \".join(palabras[:i])\n",
        "                palabra_posterior = \" \".join(palabras[i+1:i+4]) if i < len(palabras) - 3 else \" \".join(palabras[i+1:])\n",
        "\n",
        "                cambios.append((palabra, nombre_anonimizado, palabra_anterior, palabra_posterior))\n",
        "            else:\n",
        "                texto_anonimizado.append(palabra)\n",
        "        else:\n",
        "            texto_anonimizado.append(palabra)\n",
        "\n",
        "    return \" \".join(texto_anonimizado)\n",
        "\n",
        "# Cargar datos preprocesados\n",
        "df_preprocesado = pd.read_excel(\"MOSTRA_1_preprocesado.xlsx\")\n",
        "\n",
        "# Aplicar anonimización\n",
        "df_preprocesado[\"body_anonimizado\"] = df_preprocesado[\"body_preprocesado\"].apply(anonimizar_texto)\n",
        "\n",
        "# Guardar anonimizado\n",
        "df_preprocesado.to_excel(\"MOSTRA_1_anonimizado.xlsx\", index=False)\n",
        "\n",
        "# Guardar cambios en nombres\n",
        "cambios_df = pd.DataFrame(cambios, columns=[\"Original\", \"Anonimizado\", \"Palabra_Anterior\", \"Palabra_Posterior\"])\n",
        "cambios_df.to_excel(\"cambios_anonimizacion.xlsx\", index=False)\n",
        "\n",
        "print(\"Anonimización completada. Ejecutando NER para validación...\")\n",
        "\n",
        "### 🔍 Integración con spaCy NER\n",
        "def extraer_entidades(texto):\n",
        "    \"\"\"Extrae entidades nombradas de un texto usando spaCy.\"\"\"\n",
        "    doc = nlp(str(texto))\n",
        "    return {ent.text for ent in doc.ents}  # Devolver conjunto de entidades únicas\n",
        "\n",
        "# Aplicar NER en ambas versiones\n",
        "df_preprocesado[\"entidades_original\"] = df[\"body\"].apply(extraer_entidades)\n",
        "df_preprocesado[\"entidades_anonimizado\"] = df_preprocesado[\"body_anonimizado\"].apply(extraer_entidades)\n",
        "\n",
        "# Comparar entidades y decidir si revertir al texto original\n",
        "def restaurar_si_cambia(row):\n",
        "    if row[\"entidades_original\"] != row[\"entidades_anonimizado\"]:\n",
        "        return row[\"body\"]  # Restaurar original si hay cambios\n",
        "    return row[\"body_anonimizado\"]  # Mantener anonimizado si no hay cambios\n",
        "\n",
        "df_preprocesado[\"body_final\"] = df_preprocesado.apply(restaurar_si_cambia, axis=1)\n",
        "\n",
        "# Guardar resultado final\n",
        "df_preprocesado.to_excel(\"MOSTRA_1_final.xlsx\", index=False)\n",
        "\n",
        "print(\"Proceso completo. Archivo guardado como 'MOSTRA_1_final.xlsx'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ro7Hhbc5lXRp",
        "outputId": "cf556d0a-1ad9-4053-e415-18412a53e415"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting es-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from es-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Anonimización completada. Ejecutando NER para validación...\n",
            "Proceso completo. Archivo guardado como 'MOSTRA_1_final.xlsx'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "# Cargar modelo de spaCy en español\n",
        "nlp = spacy.load(\"es_core_news_sm\")\n",
        "\n",
        "# Cargar datos\n",
        "df = pd.read_excel(\"MOSTRA_1_anonimizado.xlsx\")\n",
        "df_original = pd.read_excel(\"MOSTRA_1.xlsx\")\n",
        "\n",
        "# 🔍 Función para extraer nombres de persona\n",
        "def extraer_nombres_persona(texto):\n",
        "    \"\"\"Extrae solo nombres de persona detectados por spaCy.\"\"\"\n",
        "    doc = nlp(str(texto))\n",
        "    return {ent.text for ent in doc.ents if ent.label_ == \"PER\"}  # Filtrar solo entidades de persona\n",
        "\n",
        "# Aplicar extracción de nombres de persona\n",
        "df[\"nombres_original\"] = df_original[\"body\"].apply(extraer_nombres_persona)\n",
        "df[\"nombres_anonimizado\"] = df[\"body_anonimizado\"].apply(extraer_nombres_persona)\n",
        "\n",
        "# Guardar el resultado en un archivo Excel\n",
        "df.to_excel(\"MOSTRA_1_nombres_detectados.xlsx\", index=False)\n",
        "\n",
        "# Mostrar los primeros resultados\n",
        "print(df[[\"nombres_original\", \"nombres_anonimizado\"]].head())\n",
        "\n",
        "print(\"Proceso completado. Archivo guardado como 'MOSTRA_1_nombres_detectados.xlsx'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7IiITRRnYgd",
        "outputId": "c64c8ddc-49db-4c83-d2e8-074eae9448a3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  nombres_original     nombres_anonimizado\n",
            "0               {}                      {}\n",
            "1     {Bienvenido}  {benvingutda, tatenem}\n",
            "2               {}                      {}\n",
            "3               {}                      {}\n",
            "4               {}                      {}\n",
            "Proceso completado. Archivo guardado como 'MOSTRA_1_nombres_detectados.xlsx'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import torch\n",
        "import time\n",
        "from transformers import AutoModelForTokenClassification, AutoTokenizer, pipeline\n",
        "\n",
        "# 🚀 Iniciar timer global\n",
        "inicio_total = time.time()\n",
        "\n",
        "# 🚀 Cargar modelo NER con XLM-RoBERTa\n",
        "print(\"🔹 Cargando modelo NER...\")\n",
        "inicio = time.time()\n",
        "modelo_ner = \"MMG/xlm-roberta-large-ner-spanish\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(modelo_ner)\n",
        "modelo = AutoModelForTokenClassification.from_pretrained(modelo_ner)\n",
        "nlp_ner = pipeline(\"ner\", model=modelo, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
        "print(f\"✅ Modelo cargado en {time.time() - inicio:.2f} segundos.\\n\")\n",
        "\n",
        "# 📌 Función para extraer nombres de persona con XLM-RoBERTa\n",
        "def extraer_nombres_ner(texto):\n",
        "    \"\"\"Extrae nombres de persona usando XLM-RoBERTa.\"\"\"\n",
        "    if not isinstance(texto, str) or texto.strip() == \"\":\n",
        "        return set()\n",
        "    entidades = nlp_ner(texto)\n",
        "    return {ent[\"word\"] for ent in entidades if ent[\"entity_group\"] == \"PER\"}\n",
        "\n",
        "# 📌 Función de preprocesamiento\n",
        "def preprocesar_texto(texto):\n",
        "    return re.sub(r'[^\\w\\sÁÉÍÓÚáéíóúÑñ]', '', texto.lower())\n",
        "\n",
        "# 📂 Cargar datos\n",
        "print(\"🔹 Cargando datos...\")\n",
        "inicio = time.time()\n",
        "df = pd.read_excel(\"MOSTRA_1.xlsx\")\n",
        "df[\"body_preprocesado\"] = df[\"body\"].astype(str).apply(preprocesar_texto)\n",
        "print(f\"✅ Datos cargados en {time.time() - inicio:.2f} segundos.\\n\")\n",
        "\n",
        "# 📌 Cargar lista de nombres\n",
        "print(\"🔹 Cargando lista de nombres...\")\n",
        "inicio = time.time()\n",
        "nombres_df = pd.read_csv(\"2024_pad_m_nom_sexe.csv\")\n",
        "nombres_masculinos = set(nombres_df[nombres_df[\"SEXE\"] == 2][\"NOM\"].str.strip().str.lower().tolist())\n",
        "nombres_femeninos = set(nombres_df[nombres_df[\"SEXE\"] == 1][\"NOM\"].str.strip().str.lower().tolist())\n",
        "print(f\"✅ Lista de nombres cargada en {time.time() - inicio:.2f} segundos.\\n\")\n",
        "\n",
        "# 📌 Palabras que no se deben anonimizar\n",
        "palabras_excluidas = {\"bo\", \"d'una\", \"justo\", \"salud\", \"leo\", \"te\", \"ella\", \"el\", \"los\", \"las\"}\n",
        "\n",
        "# 📌 Diccionario para mantener consistencia en la anonimización\n",
        "nombre_map = {}\n",
        "cambios = []\n",
        "\n",
        "def detectar_genero(nombre):\n",
        "    nombre = nombre.lower()\n",
        "    return \"male\" if nombre in nombres_masculinos else \"female\" if nombre in nombres_femeninos else \"neutral\"\n",
        "\n",
        "def mantener_formato(original, nuevo):\n",
        "    return nuevo.title() if original.istitle() else nuevo.upper() if original.isupper() else nuevo.lower()\n",
        "\n",
        "def generar_nombre(original_name):\n",
        "    if original_name in nombre_map:\n",
        "        return nombre_map[original_name]\n",
        "    genero = detectar_genero(original_name.split()[0])\n",
        "    nuevo_nombre = random.choice(list(nombres_masculinos if genero == \"male\" else nombres_femeninos))\n",
        "    nombre_map[original_name] = mantener_formato(original_name, nuevo_nombre)\n",
        "    return nombre_map[original_name]\n",
        "\n",
        "# 🔍 Aplicar anonimización y registrar cambios\n",
        "print(\"🔹 Iniciando anonimización...\")\n",
        "inicio = time.time()\n",
        "total_filas = len(df)\n",
        "df[\"body_anonimizado\"], df[\"cambio_realizado\"] = zip(*df[\"body_preprocesado\"].apply(lambda x: anonimizar_texto(x)))\n",
        "\n",
        "# ⏳ Tiempo total estimado\n",
        "tiempo_anonimizacion = time.time() - inicio\n",
        "print(f\"✅ Anonimización completada en {tiempo_anonimizacion:.2f} segundos.\\n\")\n",
        "\n",
        "# 🔍 Aplicar NER **solo en textos donde hubo cambios**\n",
        "print(\"🔹 Aplicando NER solo en textos modificados...\")\n",
        "inicio = time.time()\n",
        "df[\"nombres_original\"] = df.apply(lambda row: extraer_nombres_ner(row[\"body\"]) if row[\"cambio_realizado\"] else set(), axis=1)\n",
        "df[\"nombres_anonimizado\"] = df.apply(lambda row: extraer_nombres_ner(row[\"body_anonimizado\"]) if row[\"cambio_realizado\"] else set(), axis=1)\n",
        "print(f\"✅ NER aplicado en {time.time() - inicio:.2f} segundos.\\n\")\n",
        "\n",
        "# 📌 Comparar nombres detectados antes y después de la anonimización\n",
        "print(\"🔹 Comparando nombres originales y anonimizados...\")\n",
        "inicio = time.time()\n",
        "df[\"body_final\"] = df.apply(lambda row: row[\"body\"] if row[\"nombres_original\"] != row[\"nombres_anonimizado\"] else row[\"body_anonimizado\"], axis=1)\n",
        "print(f\"✅ Comparación completada en {time.time() - inicio:.2f} segundos.\\n\")\n",
        "\n",
        "# 📂 Guardar resultado final\n",
        "print(\"🔹 Guardando resultado final...\")\n",
        "inicio = time.time()\n",
        "df.to_excel(\"MOSTRA_1_final.xlsx\", index=False)\n",
        "print(f\"✅ Archivo guardado en {time.time() - inicio:.2f} segundos.\\n\")\n",
        "\n",
        "# ⏳ Tiempo total de ejecución\n",
        "print(f\"⏳ Tiempo total de ejecución: {time.time() - inicio_total:.2f} segundos.\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYt33VZypJNU",
        "outputId": "3e295a2d-f0c4-494b-def7-4d6b28b848bc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Cargando modelo NER...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo cargado en 6.16 segundos.\n",
            "\n",
            "🔹 Cargando datos...\n",
            "✅ Datos cargados en 4.64 segundos.\n",
            "\n",
            "🔹 Cargando lista de nombres...\n",
            "✅ Lista de nombres cargada en 0.01 segundos.\n",
            "\n",
            "🔹 Iniciando anonimización...\n",
            "✅ Anonimización completada en 0.10 segundos.\n",
            "\n",
            "🔹 Aplicando NER solo en textos modificados...\n",
            "✅ NER aplicado en 851.36 segundos.\n",
            "\n",
            "🔹 Comparando nombres originales y anonimizados...\n",
            "✅ Comparación completada en 0.09 segundos.\n",
            "\n",
            "🔹 Guardando resultado final...\n",
            "✅ Archivo guardado en 5.58 segundos.\n",
            "\n",
            "⏳ Tiempo total de ejecución: 867.95 segundos.\n"
          ]
        }
      ]
    }
  ]
}